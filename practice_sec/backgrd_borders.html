<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Backgrounds</title>
    <link rel="stylesheet" href="css_bg.css">
</head>

<body>
    <h1>Big Data</h1>
    <div class="about">
        <p>
                Big data" is a field that treats ways to analyze, systematically extract information from, or otherwise deal with data sets that are too large or complex to be dealt with by traditional data-processing application software. Data with many cases (rows) offer greater statistical power, while data with higher complexity (more attributes or columns) may lead to a higher false discovery rate
        </p>
    </div>
    <div class="about">
        <p id="second-para">Current usage of the term big data tends to refer to the use of predictive analytics, user behavior analytics, or certain other advanced data analytics methods that extract value from data, and seldom to a particular size of data set. "There is little doubt that the quantities of data now available are indeed large, but that's not the most relevant characteristic of this new data ecosystem.</p>
    </div>
    <div class="arch">
        <h2>Architecture</h2>
        <p id='first-para'><a href="https://en.wikipedia.org/wiki/Teradata">Teradata</a>  Corporation in 1984 marketed the parallel processing DBC 1012 system. Teradata systems were the first to store and analyze 1 terabyte of data in 1992. Hard disk drives were 2.5 GB in 1991 so the definition of big data continuously evolves according to Kryder's Law. Teradata installed the first petabyte class RDBMS based system in 2007. As of 2017, there are a few dozen petabyte class Teradata relational databases installed, the largest of which exceeds 50 PB. Systems up until 2008 were 100% structured relational data. Since then, Teradata has added unstructured data types including XML, JSON, and Avro.</p>
    </div>
    <div class="arch">
        <ul id='list-data'>
            <li>Connection</li>
            <li>cloud</li>
            <li>Cyber</li>
            <li>Community</li>

        </ul>
    </div>
    <p id="third-para">
            A 2016 definition states that "Big data represents the information assets characterized by such a high volume, velocity and variety to require specific technology and analytical methods for its transformation into value".[25] Similarly, Kaplan and Haenlein define big data as "data sets characterized by huge amounts (volume) of frequently updated data (velocity) in various formats, such as numeric, textual, or images/videos (variety)."[26] Additionally, a new V, veracity, is added by some organizations to describe it,[27] revisionism challenged by some industry authorities.[28] The three Vs (volume, variety and velocity) has been further expanded to other complementary characteristics of big data:[29][30]
    </p>
    <p>
            Multidimensional big data can also be represented as data cubes or, mathematically, tensors. Array Database Systems have set out to provide storage and high-level query support on this data type. Additional technologies being applied to big data include efficient tensor-based computation,[57] such as multilinear subspace learning.,[58] massively parallel-processing (MPP) databases, search-based applications, data mining,[59] distributed file systems, distributed databases, cloud and HPC-based infrastructure (applications, storage and computing resources)[60] and the Internet.[citation needed] Although, many approaches and technologies have been developed, it still remains difficult to carry out machine learning with big data.[61]
    </p>
    <br><br>
    <p>Some MPP relational databases have the ability to store and manage petabytes of data. Implicit is the ability to load, monitor, back up, and optimize the use of the large data tables in the RDBMS.[62][promotional source?]

            DARPA's Topological Data Analysis program seeks the fundamental structure of massive data sets and in 2008 the technology went public with the launch of a company called Ayasdi.[63][third-party source needed]
            
            The practitioners of big data analytics processes are generally hostile to slower shared storage,[64] preferring direct-attached storage (DAS) in its various forms from solid state drive (SSD) to high capacity SATA disk buried inside parallel processing nodes. The perception of shared storage architectures—Storage area network (SAN) and Network-attached storage (NAS) —is that they are relatively slow, complex, and expensive. These qualities are not consistent with big data analytics systems that thrive on system performance, commodity infrastructure, and low cost.
            .</p>
            <p>
            Real or near-real time information delivery is one of the defining characteristics of big data analytics. Latency is therefore avoided whenever and wherever possible. Data in memory is good—data on spinning disk at the other end of a FC SAN connection is not. The cost of a SAN at the scale needed for analytics applications is very much higher than other storage techniques
        </p>
</body>
</html>